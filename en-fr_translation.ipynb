{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from datasets import load_dataset\n\nbooks = load_dataset(\"opus_books\", \"en-fr\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-12T10:23:40.455246Z","iopub.execute_input":"2025-04-12T10:23:40.455797Z","iopub.status.idle":"2025-04-12T10:23:42.281988Z","shell.execute_reply.started":"2025-04-12T10:23:40.455773Z","shell.execute_reply":"2025-04-12T10:23:42.281450Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"books = books[\"train\"].train_test_split(test_size=0.2)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-12T10:23:50.945174Z","iopub.execute_input":"2025-04-12T10:23:50.945615Z","iopub.status.idle":"2025-04-12T10:23:50.982887Z","shell.execute_reply.started":"2025-04-12T10:23:50.945593Z","shell.execute_reply":"2025-04-12T10:23:50.982370Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"books[\"train\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-12T10:23:55.358069Z","iopub.execute_input":"2025-04-12T10:23:55.358332Z","iopub.status.idle":"2025-04-12T10:23:55.363978Z","shell.execute_reply.started":"2025-04-12T10:23:55.358314Z","shell.execute_reply":"2025-04-12T10:23:55.363486Z"}},"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['id', 'translation'],\n    num_rows: 101668\n})"},"metadata":{}}],"execution_count":31},{"cell_type":"code","source":"books['train'][1]['translation']\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-12T08:43:03.448613Z","iopub.execute_input":"2025-04-12T08:43:03.449308Z","iopub.status.idle":"2025-04-12T08:43:03.454438Z","shell.execute_reply.started":"2025-04-12T08:43:03.449284Z","shell.execute_reply":"2025-04-12T08:43:03.453768Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"{'en': 'In the morning we were both at our penitentials; I cried very heartily, he expressed himself very sorry; but that was all either of us could do at that time, and the way being thus cleared, and the bars of virtue and conscience thus removed, we had the less difficult afterwards to struggle with.',\n 'fr': \"Le matin nous fûmes tous deux à nos repentailles; je pleurai de tout coeur, et lui-même reconnut son chagrin; mais c'est tout ce que nous pouvions faire l'un et l'autre; et la route étant ainsi débarrassée, les barrières de la vertu et de la conscience renversées, nous eûmes à lutter contre moins d'obstacles.\"}"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\ncheckpoint = \"google-t5/t5-small\"\ntokenizer = AutoTokenizer.from_pretrained(checkpoint)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-12T08:43:07.450650Z","iopub.execute_input":"2025-04-12T08:43:07.450929Z","iopub.status.idle":"2025-04-12T08:43:22.007946Z","shell.execute_reply.started":"2025-04-12T08:43:07.450906Z","shell.execute_reply":"2025-04-12T08:43:22.007119Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/2.32k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7059d770dcb94dcdb24e76c242f2fdf1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f616e493cfd54e0c83fcab17be6f6913"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f60668d3f94941d28c5ff5e9b90b12a5"}},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"source_lang = \"en\"\ntarget_lang = \"fr\"\nprefix = \"translate English to French: \"\n\n\ndef preprocess_function(examples):\n    inputs = [prefix + example[source_lang] for example in examples[\"translation\"]]\n    targets = [example[target_lang] for example in examples[\"translation\"]]\n    model_inputs = tokenizer(inputs, text_target=targets, max_length=128, truncation=True)\n    return model_inputs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-12T08:43:25.191752Z","iopub.execute_input":"2025-04-12T08:43:25.192232Z","iopub.status.idle":"2025-04-12T08:43:25.197672Z","shell.execute_reply.started":"2025-04-12T08:43:25.192206Z","shell.execute_reply":"2025-04-12T08:43:25.196779Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"tokenized_books = books.map(preprocess_function, batched=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-12T08:43:34.579058Z","iopub.execute_input":"2025-04-12T08:43:34.579572Z","iopub.status.idle":"2025-04-12T08:43:55.531008Z","shell.execute_reply.started":"2025-04-12T08:43:34.579549Z","shell.execute_reply":"2025-04-12T08:43:55.530310Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/101668 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3460cb0071ed4239b7bea37d3a9ce6fe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/25417 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6d4e5b98f48d4e539b7d04cf3074f4d1"}},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"from transformers import DataCollatorForSeq2Seq\n\ndata_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=checkpoint)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-12T08:44:01.383592Z","iopub.execute_input":"2025-04-12T08:44:01.384107Z","iopub.status.idle":"2025-04-12T08:44:21.483662Z","shell.execute_reply.started":"2025-04-12T08:44:01.384062Z","shell.execute_reply":"2025-04-12T08:44:21.483100Z"}},"outputs":[{"name":"stderr","text":"2025-04-12 08:44:04.784881: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1744447445.220343      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1744447445.355233      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"!pip install evaluate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-12T08:44:49.965255Z","iopub.execute_input":"2025-04-12T08:44:49.966374Z","iopub.status.idle":"2025-04-12T08:44:56.172092Z","shell.execute_reply.started":"2025-04-12T08:44:49.966346Z","shell.execute_reply":"2025-04-12T08:44:56.171128Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Collecting evaluate\n  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from evaluate) (1.26.4)\nRequirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.3)\nRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.3)\nRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\nRequirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.3.2)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.30.2)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (24.2)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.18.0)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (19.0.1)\nCollecting fsspec>=2021.05.0 (from fsspec[http]>=2021.05.0->evaluate)\n  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.11.16)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.13.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2025.1.31)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.2.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.19.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->evaluate) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->evaluate) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->evaluate) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->evaluate) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->evaluate) (2024.2.0)\nDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: fsspec, evaluate\n  Attempting uninstall: fsspec\n    Found existing installation: fsspec 2025.3.2\n    Uninstalling fsspec-2025.3.2:\n      Successfully uninstalled fsspec-2025.3.2\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.12.0 which is incompatible.\ntorch 2.5.1+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.8.4.1 which is incompatible.\ntorch 2.5.1+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\ntorch 2.5.1+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.3.3.83 which is incompatible.\ntorch 2.5.1+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.9.90 which is incompatible.\ntorch 2.5.1+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.7.3.90 which is incompatible.\ntorch 2.5.1+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.8.93 which is incompatible.\ntorch 2.5.1+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.8.93 which is incompatible.\nbigframes 1.36.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed evaluate-0.4.3 fsspec-2024.12.0\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"import evaluate\n\nmetric = evaluate.load(\"sacrebleu\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-12T08:45:30.524782Z","iopub.execute_input":"2025-04-12T08:45:30.525436Z","iopub.status.idle":"2025-04-12T08:45:31.042534Z","shell.execute_reply.started":"2025-04-12T08:45:30.525406Z","shell.execute_reply":"2025-04-12T08:45:31.041925Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"!pip install -q sacrebleu","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-12T08:45:22.152292Z","iopub.execute_input":"2025-04-12T08:45:22.153013Z","iopub.status.idle":"2025-04-12T08:45:25.602105Z","shell.execute_reply.started":"2025-04-12T08:45:22.152988Z","shell.execute_reply":"2025-04-12T08:45:25.601390Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"import numpy as np\n\n\ndef postprocess_text(preds, labels):\n    preds = [pred.strip() for pred in preds]\n    labels = [[label.strip()] for label in labels]\n\n    return preds, labels\n\n\ndef compute_metrics(eval_preds):\n    preds, labels = eval_preds\n    if isinstance(preds, tuple):\n        preds = preds[0]\n    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n\n    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n\n    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n\n    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n    result = {\"bleu\": result[\"score\"]}\n\n    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n    result[\"gen_len\"] = np.mean(prediction_lens)\n    result = {k: round(v, 4) for k, v in result.items()}\n    return result","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-12T08:45:51.048646Z","iopub.execute_input":"2025-04-12T08:45:51.050270Z","iopub.status.idle":"2025-04-12T08:45:51.055971Z","shell.execute_reply.started":"2025-04-12T08:45:51.050242Z","shell.execute_reply":"2025-04-12T08:45:51.055276Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"from transformers import AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer\n\nmodel = AutoModelForSeq2SeqLM.from_pretrained(checkpoint)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-12T08:45:55.312959Z","iopub.execute_input":"2025-04-12T08:45:55.313684Z","iopub.status.idle":"2025-04-12T08:45:59.541681Z","shell.execute_reply.started":"2025-04-12T08:45:55.313658Z","shell.execute_reply":"2025-04-12T08:45:59.540909Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"657665763f7e40e99c8d74c9ec7d502f"}},"metadata":{}},{"name":"stderr","text":"Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"968b800b3d8c4040b49568fc90e50117"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6c099abb681a4e3ab1f17d84fe4e0437"}},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"from huggingface_hub import notebook_login\n\nnotebook_login()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-12T08:46:08.605668Z","iopub.execute_input":"2025-04-12T08:46:08.605987Z","iopub.status.idle":"2025-04-12T08:46:08.625209Z","shell.execute_reply.started":"2025-04-12T08:46:08.605964Z","shell.execute_reply":"2025-04-12T08:46:08.624244Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1edda679336444cc9f39bcfe1246c9c9"}},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"training_args = Seq2SeqTrainingArguments(\n    output_dir=\"my_awesome_opus_books_model\",\n    eval_strategy=\"epoch\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=16,\n    weight_decay=0.01,\n    save_total_limit=3,\n    num_train_epochs=2,\n    predict_with_generate=True,\n    fp16=True, #change to bf16=True for XPU\n    push_to_hub=True,\n)\n\ntrainer = Seq2SeqTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_books[\"train\"],\n    eval_dataset=tokenized_books[\"test\"],\n    processing_class=tokenizer,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics,\n)\n\ntrainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-12T08:49:44.572917Z","iopub.execute_input":"2025-04-12T08:49:44.573484Z","iopub.status.idle":"2025-04-12T09:34:57.287430Z","shell.execute_reply.started":"2025-04-12T08:49:44.573460Z","shell.execute_reply":"2025-04-12T09:34:57.286829Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250412_084945-gbkes6bf</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/personal-12345/huggingface/runs/gbkes6bf' target=\"_blank\">my_awesome_opus_books_model</a></strong> to <a href='https://wandb.ai/personal-12345/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/personal-12345/huggingface' target=\"_blank\">https://wandb.ai/personal-12345/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/personal-12345/huggingface/runs/gbkes6bf' target=\"_blank\">https://wandb.ai/personal-12345/huggingface/runs/gbkes6bf</a>"},"metadata":{}},{"name":"stderr","text":"Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\nPassing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='6356' max='6356' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [6356/6356 45:01, Epoch 2/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Bleu</th>\n      <th>Gen Len</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.896600</td>\n      <td>1.656555</td>\n      <td>5.832000</td>\n      <td>18.372900</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.846600</td>\n      <td>1.634732</td>\n      <td>6.026700</td>\n      <td>18.357700</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=6356, training_loss=1.9051137723736675, metrics={'train_runtime': 2712.116, 'train_samples_per_second': 74.973, 'train_steps_per_second': 2.344, 'total_flos': 5758591697289216.0, 'train_loss': 1.9051137723736675, 'epoch': 2.0})"},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"trainer.push_to_hub()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-12T10:04:11.491280Z","iopub.execute_input":"2025-04-12T10:04:11.491568Z","iopub.status.idle":"2025-04-12T10:04:14.941002Z","shell.execute_reply.started":"2025-04-12T10:04:11.491548Z","shell.execute_reply":"2025-04-12T10:04:14.940440Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"events.out.tfevents.1744447785.3831de97e65e.31.1:   0%|          | 0.00/9.62k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"39432db7d1bd44f5bde57da1ed6b6e47"}},"metadata":{}},{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/Fulwa/my_awesome_opus_books_model/commit/46609e6af9d5f7e1e898a400af1fc11b16ddc2f6', commit_message='End of training', commit_description='', oid='46609e6af9d5f7e1e898a400af1fc11b16ddc2f6', pr_url=None, repo_url=RepoUrl('https://huggingface.co/Fulwa/my_awesome_opus_books_model', endpoint='https://huggingface.co', repo_type='model', repo_id='Fulwa/my_awesome_opus_books_model'), pr_revision=None, pr_num=None)"},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"text = 'translate English to French: Hello,how are you'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-12T10:11:37.998652Z","iopub.execute_input":"2025-04-12T10:11:37.999232Z","iopub.status.idle":"2025-04-12T10:11:38.003447Z","shell.execute_reply.started":"2025-04-12T10:11:37.999209Z","shell.execute_reply":"2025-04-12T10:11:38.002911Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"from transformers import pipeline\n\ntranslator = pipeline(\"translation_xx_to_yy\", model=\"Fulwa/my_awesome_opus_books_model\")\ntranslator(text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-12T10:11:39.192372Z","iopub.execute_input":"2025-04-12T10:11:39.193011Z","iopub.status.idle":"2025-04-12T10:11:39.634096Z","shell.execute_reply.started":"2025-04-12T10:11:39.192989Z","shell.execute_reply":"2025-04-12T10:11:39.633522Z"}},"outputs":[{"name":"stderr","text":"Device set to use cuda:0\n","output_type":"stream"},{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"[{'translation_text': 'Bonjour, comment êtes-vous'}]"},"metadata":{}}],"execution_count":25},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nsecret_value_0 = user_secrets.get_secret(\"w&b\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-12T08:49:30.548915Z","iopub.execute_input":"2025-04-12T08:49:30.549260Z","iopub.status.idle":"2025-04-12T08:49:30.673586Z","shell.execute_reply.started":"2025-04-12T08:49:30.549229Z","shell.execute_reply":"2025-04-12T08:49:30.672840Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"import wandb\n\nwandb.login(key=secret_value_0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-12T08:49:32.697404Z","iopub.execute_input":"2025-04-12T08:49:32.697674Z","iopub.status.idle":"2025-04-12T08:49:32.754069Z","shell.execute_reply.started":"2025-04-12T08:49:32.697654Z","shell.execute_reply":"2025-04-12T08:49:32.753476Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mfulwaasheeb00008\u001b[0m (\u001b[33mpersonal-12345\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"wandb.init()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-12T08:49:23.340206Z","iopub.status.idle":"2025-04-12T08:49:23.340748Z","shell.execute_reply.started":"2025-04-12T08:49:23.340578Z","shell.execute_reply":"2025-04-12T08:49:23.340594Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}